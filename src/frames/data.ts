/**
 * Data Frames - Content carrier frames that are processed in order.
 *
 * Data frames contain the actual content being processed through the pipeline,
 * such as audio, text, images, and transcriptions. These frames are susceptible
 * to user interruptions and are processed in the order they are received.
 */

import { DataFrame, formatPts } from "./base";

/**
 * Audio format configuration for audio frames
 */
export interface AudioConfig {
  /** Sample rate in Hz (e.g., 16000, 44100, 48000) */
  sampleRate: number;
  /** Number of audio channels (1 for mono, 2 for stereo) */
  numChannels: number;
}

/**
 * Base class for audio frames containing raw PCM audio data.
 */
export abstract class AudioRawFrame extends DataFrame {
  /** Raw PCM audio data as bytes */
  readonly audio: Uint8Array;
  /** Sample rate in Hz */
  readonly sampleRate: number;
  /** Number of audio channels */
  readonly numChannels: number;
  /** Number of audio frames (samples per channel) */
  readonly numFrames: number;

  constructor(audio: Uint8Array, sampleRate: number, numChannels: number) {
    super();
    this.audio = audio;
    this.sampleRate = sampleRate;
    this.numChannels = numChannels;
    // Calculate number of frames (assuming 16-bit audio = 2 bytes per sample)
    this.numFrames = Math.floor(audio.length / (numChannels * 2));
  }

  /**
   * Get the duration of this audio frame in seconds
   */
  get duration(): number {
    return this.numFrames / this.sampleRate;
  }

  /**
   * Get the duration of this audio frame in milliseconds
   */
  get durationMs(): number {
    return (this.numFrames / this.sampleRate) * 1000;
  }
}

/**
 * Raw audio input data frame.
 *
 * Contains raw PCM audio data received from input sources such as
 * microphones or audio streams. This frame is typically processed by
 * STT services to generate transcriptions.
 *
 * @example
 * ```typescript
 * // Create an input audio frame from microphone data
 * const audioFrame = new InputAudioRawFrame(
 *   audioBuffer,
 *   16000, // 16kHz sample rate
 *   1      // mono
 * );
 * ```
 */
export class InputAudioRawFrame extends AudioRawFrame {
  constructor(audio: Uint8Array, sampleRate: number, numChannels: number) {
    super(audio, sampleRate, numChannels);
  }

  override toString(): string {
    const pts = formatPts(this.pts);
    return `${this.name}(pts: ${pts}, size: ${this.audio.length}, frames: ${this.numFrames}, sample_rate: ${this.sampleRate}, channels: ${this.numChannels})`;
  }
}

/**
 * Processed audio output data frame.
 *
 * Contains raw PCM audio data to be sent to output destinations such as
 * speakers or audio streams. This is typically produced by TTS services.
 *
 * @example
 * ```typescript
 * // Create an output audio frame for playback
 * const audioFrame = new OutputAudioRawFrame(
 *   ttsAudioBuffer,
 *   24000, // 24kHz sample rate
 *   1      // mono
 * );
 * ```
 */
export class OutputAudioRawFrame extends AudioRawFrame {
  constructor(audio: Uint8Array, sampleRate: number, numChannels: number) {
    super(audio, sampleRate, numChannels);
  }

  override toString(): string {
    const pts = formatPts(this.pts);
    return `${this.name}(pts: ${pts}, destination: ${this.transportDestination ?? "N/A"}, size: ${this.audio.length}, frames: ${this.numFrames}, sample_rate: ${this.sampleRate}, channels: ${this.numChannels})`;
  }
}

/**
 * Audio data frame generated by Text-to-Speech services.
 *
 * A specialized output audio frame specifically for TTS-generated audio.
 * This allows processors to distinguish between TTS audio and other
 * audio sources.
 */
export class TTSAudioRawFrame extends OutputAudioRawFrame {
  constructor(audio: Uint8Array, sampleRate: number, numChannels: number) {
    super(audio, sampleRate, numChannels);
  }
}

/**
 * Text content frame.
 *
 * Contains text data flowing through the pipeline. This is commonly used
 * for LLM responses, user input text, and other textual content.
 *
 * @example
 * ```typescript
 * const textFrame = new TextFrame("Hello, how can I help you today?");
 * ```
 */
export class TextFrame extends DataFrame {
  /** The text content */
  readonly text: string;
  /** Whether this text should skip TTS processing */
  skipTts: boolean;

  constructor(text: string) {
    super();
    this.text = text;
    this.skipTts = false;
  }

  override toString(): string {
    const pts = formatPts(this.pts);
    return `${this.name}(pts: ${pts}, text: [${this.text}])`;
  }
}

/**
 * Supported language codes for transcription
 */
export type Language =
  | "en"
  | "en-US"
  | "en-GB"
  | "es"
  | "fr"
  | "de"
  | "it"
  | "pt"
  | "nl"
  | "ja"
  | "ko"
  | "zh"
  | "zh-CN"
  | "zh-TW"
  | string;

/**
 * Text frame containing speech transcription data.
 *
 * A text frame with transcription-specific data including user identification,
 * timestamps, and the raw STT service result. This is produced by STT services
 * and consumed by LLM processors.
 *
 * @example
 * ```typescript
 * const transcription = new TranscriptionFrame(
 *   "Hello world",
 *   "user-123",
 *   new Date().toISOString(),
 *   "en-US"
 * );
 * ```
 */
export class TranscriptionFrame extends TextFrame {
  /** Identifier for the user who spoke */
  readonly userId: string;
  /** ISO 8601 timestamp when the transcription occurred */
  readonly timestamp: string;
  /** Detected or specified language of the speech */
  readonly language?: Language;
  /** Raw result from the STT service, if available */
  readonly result?: unknown;

  constructor(
    text: string,
    userId: string,
    timestamp: string,
    language?: Language,
    result?: unknown
  ) {
    super(text);
    this.userId = userId;
    this.timestamp = timestamp;
    this.language = language;
    this.result = result;
  }

  override toString(): string {
    return `${this.name}(user: ${this.userId}, text: [${this.text}], language: ${this.language ?? "N/A"}, timestamp: ${this.timestamp})`;
  }
}

/**
 * Text frame containing partial/interim transcription data.
 *
 * Contains partial results before final transcription is available.
 * These frames are useful for real-time display but should not be
 * used for final processing.
 *
 * @example
 * ```typescript
 * const interim = new InterimTranscriptionFrame(
 *   "Hello wor",
 *   "user-123",
 *   new Date().toISOString()
 * );
 * ```
 */
export class InterimTranscriptionFrame extends TextFrame {
  /** Identifier for the user who spoke */
  readonly userId: string;
  /** ISO 8601 timestamp when the transcription occurred */
  readonly timestamp: string;
  /** Raw result from the STT service, if available */
  readonly result?: unknown;

  constructor(text: string, userId: string, timestamp: string, result?: unknown) {
    super(text);
    this.userId = userId;
    this.timestamp = timestamp;
    this.result = result;
  }

  override toString(): string {
    return `${this.name}(user: ${this.userId}, text: [${this.text}], timestamp: ${this.timestamp})`;
  }
}

/**
 * Frame containing LLM-generated text.
 *
 * A specialized text frame for LLM responses, allowing processors to
 * distinguish between LLM output and other text sources.
 */
export class LLMTextFrame extends TextFrame {
  constructor(text: string) {
    super(text);
  }
}

/**
 * Frame containing an image.
 *
 * Contains image data for vision-capable processors and LLMs.
 */
export class ImageRawFrame extends DataFrame {
  /** Raw image data */
  readonly image: Uint8Array;
  /** Image width in pixels */
  readonly width: number;
  /** Image height in pixels */
  readonly height: number;
  /** Image format (e.g., 'jpeg', 'png', 'webp') */
  readonly format: string;

  constructor(image: Uint8Array, width: number, height: number, format: string) {
    super();
    this.image = image;
    this.width = width;
    this.height = height;
    this.format = format;
  }

  override toString(): string {
    return `${this.name}(size: ${this.image.length}, dimensions: ${this.width}x${this.height}, format: ${this.format})`;
  }
}

/**
 * Frame indicating user has started speaking.
 *
 * Sent by VAD when speech is detected. Used for managing conversation
 * turns and potentially triggering interruptions.
 */
export class UserStartedSpeakingFrame extends DataFrame {
  /** Whether this frame was generated by emulated VAD */
  readonly emulated: boolean;

  constructor(emulated: boolean = false) {
    super();
    this.emulated = emulated;
  }

  override toString(): string {
    return `${this.name}(emulated: ${this.emulated})`;
  }
}

/**
 * Frame indicating user has stopped speaking.
 *
 * Sent by VAD when speech ends. Used for managing conversation turns
 * and triggering transcription processing.
 */
export class UserStoppedSpeakingFrame extends DataFrame {
  /** Whether this frame was generated by emulated VAD */
  readonly emulated: boolean;

  constructor(emulated: boolean = false) {
    super();
    this.emulated = emulated;
  }

  override toString(): string {
    return `${this.name}(emulated: ${this.emulated})`;
  }
}

/**
 * Frame indicating bot has started speaking.
 *
 * Sent when TTS audio playback begins.
 */
export class BotStartedSpeakingFrame extends DataFrame {
  constructor() {
    super();
  }
}

/**
 * Frame indicating bot has stopped speaking.
 *
 * Sent when TTS audio playback completes.
 */
export class BotStoppedSpeakingFrame extends DataFrame {
  constructor() {
    super();
  }
}

/**
 * Frame containing transport message data for input.
 *
 * Used for receiving messages from transport layers (e.g., WebSocket).
 */
export class InputTransportMessageFrame extends DataFrame {
  /** The message payload */
  readonly message: Record<string, unknown>;

  constructor(message: Record<string, unknown>) {
    super();
    this.message = message;
  }

  override toString(): string {
    return `${this.name}(message: ${JSON.stringify(this.message)})`;
  }
}

/**
 * Frame containing transport message data for output.
 *
 * Used for sending messages through transport layers (e.g., WebSocket).
 */
export class OutputTransportMessageFrame extends DataFrame {
  /** The message payload */
  readonly message: Record<string, unknown>;

  constructor(message: Record<string, unknown>) {
    super();
    this.message = message;
  }

  override toString(): string {
    return `${this.name}(message: ${JSON.stringify(this.message)})`;
  }
}

/**
 * Urgent transport message frame that bypasses normal queuing.
 */
export class OutputTransportMessageUrgentFrame extends OutputTransportMessageFrame {
  constructor(message: Record<string, unknown>) {
    super(message);
  }
}

// Type guards for data frames

export function isInputAudioRawFrame(frame: unknown): frame is InputAudioRawFrame {
  return frame instanceof InputAudioRawFrame;
}

export function isOutputAudioRawFrame(frame: unknown): frame is OutputAudioRawFrame {
  return frame instanceof OutputAudioRawFrame;
}

export function isTTSAudioRawFrame(frame: unknown): frame is TTSAudioRawFrame {
  return frame instanceof TTSAudioRawFrame;
}

export function isTextFrame(frame: unknown): frame is TextFrame {
  return frame instanceof TextFrame;
}

export function isTranscriptionFrame(frame: unknown): frame is TranscriptionFrame {
  return frame instanceof TranscriptionFrame;
}

export function isInterimTranscriptionFrame(
  frame: unknown
): frame is InterimTranscriptionFrame {
  return frame instanceof InterimTranscriptionFrame;
}

export function isLLMTextFrame(frame: unknown): frame is LLMTextFrame {
  return frame instanceof LLMTextFrame;
}

export function isImageRawFrame(frame: unknown): frame is ImageRawFrame {
  return frame instanceof ImageRawFrame;
}

export function isUserStartedSpeakingFrame(
  frame: unknown
): frame is UserStartedSpeakingFrame {
  return frame instanceof UserStartedSpeakingFrame;
}

export function isUserStoppedSpeakingFrame(
  frame: unknown
): frame is UserStoppedSpeakingFrame {
  return frame instanceof UserStoppedSpeakingFrame;
}

export function isBotStartedSpeakingFrame(
  frame: unknown
): frame is BotStartedSpeakingFrame {
  return frame instanceof BotStartedSpeakingFrame;
}

export function isBotStoppedSpeakingFrame(
  frame: unknown
): frame is BotStoppedSpeakingFrame {
  return frame instanceof BotStoppedSpeakingFrame;
}

export function isInputTransportMessageFrame(
  frame: unknown
): frame is InputTransportMessageFrame {
  return frame instanceof InputTransportMessageFrame;
}

export function isOutputTransportMessageFrame(
  frame: unknown
): frame is OutputTransportMessageFrame {
  return frame instanceof OutputTransportMessageFrame;
}

